{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca348643-ff99-4a90-8c07-cb3b73941cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ab0bc6-45cc-4f65-850c-05db918eb3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'Malignant'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wisconsin = pd.read_csv(\"D:/Training/Academy/ML(Python)/Cases/Wisconsin/BreastCancer.csv\", index_col=0)\n",
    "le = LabelEncoder()\n",
    "wisconsin['Class'] = le.fit_transform( wisconsin['Class'] )\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "114e19d5-ec99-4d04-89dd-8356b1713698",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = wisconsin.drop('Class', axis=1), wisconsin['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "116e394b-94fb-4709-ae88-aad28bcd6745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-10.13685623]),\n",
       " array([[ 0.54707603,  0.04474491,  0.20952885,  0.19219542, -0.00722953,\n",
       "          0.39656381,  0.60692755,  0.19441253,  0.53085196]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.intercept_, lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9253285-7672-401c-9e5f-a991df17ce0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49c6d729-18be-4076-bccd-232ef74c5dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.98120767e-01, 1.87923285e-03],\n",
       "       [9.98229749e-01, 1.77025092e-03],\n",
       "       [1.96481629e-04, 9.99803518e-01],\n",
       "       [9.82482033e-01, 1.75179672e-02],\n",
       "       [9.94408267e-01, 5.59173308e-03],\n",
       "       [5.51665724e-01, 4.48334276e-01],\n",
       "       [2.05397996e-03, 9.97946020e-01],\n",
       "       [9.76178351e-01, 2.38216491e-02],\n",
       "       [9.98597104e-01, 1.40289575e-03],\n",
       "       [9.96557412e-01, 3.44258849e-03],\n",
       "       [9.99275706e-01, 7.24293521e-04],\n",
       "       [9.98134279e-01, 1.86572114e-03],\n",
       "       [5.46197681e-04, 9.99453802e-01],\n",
       "       [9.89788038e-01, 1.02119620e-02],\n",
       "       [9.89788038e-01, 1.02119620e-02],\n",
       "       [9.98903064e-01, 1.09693596e-03],\n",
       "       [1.16178478e-01, 8.83821522e-01],\n",
       "       [9.98911740e-01, 1.08825963e-03],\n",
       "       [9.98911740e-01, 1.08825963e-03],\n",
       "       [9.90375598e-01, 9.62440163e-03],\n",
       "       [9.96542540e-01, 3.45746032e-03],\n",
       "       [7.31077129e-01, 2.68922871e-01],\n",
       "       [4.51767821e-04, 9.99548232e-01],\n",
       "       [4.26536006e-02, 9.57346399e-01],\n",
       "       [9.95884116e-01, 4.11588442e-03],\n",
       "       [9.94408267e-01, 5.59173308e-03],\n",
       "       [1.76482335e-06, 9.99998235e-01],\n",
       "       [9.98920472e-01, 1.07952819e-03],\n",
       "       [9.94367923e-01, 5.63207664e-03],\n",
       "       [9.92801046e-01, 7.19895413e-03],\n",
       "       [9.00546648e-04, 9.99099453e-01],\n",
       "       [2.26091645e-02, 9.77390836e-01],\n",
       "       [9.96944604e-01, 3.05539560e-03],\n",
       "       [6.65540679e-01, 3.34459321e-01],\n",
       "       [1.37678737e-04, 9.99862321e-01],\n",
       "       [9.98229749e-01, 1.77025092e-03],\n",
       "       [9.81710237e-01, 1.82897629e-02],\n",
       "       [9.98120767e-01, 1.87923285e-03],\n",
       "       [9.96557412e-01, 3.44258849e-03],\n",
       "       [9.84097287e-01, 1.59027133e-02],\n",
       "       [9.98974899e-01, 1.02510133e-03],\n",
       "       [3.39111684e-03, 9.96608883e-01],\n",
       "       [9.94065422e-01, 5.93457820e-03],\n",
       "       [9.75314849e-01, 2.46851514e-02],\n",
       "       [1.25809447e-01, 8.74190553e-01],\n",
       "       [1.75295514e-04, 9.99824704e-01],\n",
       "       [1.51993916e-04, 9.99848006e-01],\n",
       "       [5.87139888e-03, 9.94128601e-01],\n",
       "       [9.68711440e-01, 3.12885599e-02],\n",
       "       [6.29203631e-03, 9.93707964e-01],\n",
       "       [9.98229749e-01, 1.77025092e-03],\n",
       "       [9.99128675e-01, 8.71325370e-04],\n",
       "       [9.90375598e-01, 9.62440163e-03],\n",
       "       [9.98911740e-01, 1.08825963e-03],\n",
       "       [9.92280983e-01, 7.71901718e-03],\n",
       "       [9.87723682e-01, 1.22763178e-02],\n",
       "       [1.42121671e-05, 9.99985788e-01],\n",
       "       [2.01941669e-02, 9.79805833e-01],\n",
       "       [3.62773411e-04, 9.99637227e-01],\n",
       "       [9.98005089e-01, 1.99491063e-03],\n",
       "       [9.96756762e-01, 3.24323782e-03],\n",
       "       [9.88359857e-01, 1.16401429e-02],\n",
       "       [9.98120767e-01, 1.87923285e-03],\n",
       "       [8.12267661e-04, 9.99187732e-01],\n",
       "       [4.34721034e-01, 5.65278966e-01],\n",
       "       [9.83412527e-01, 1.65874726e-02],\n",
       "       [9.89996448e-01, 1.00035519e-02],\n",
       "       [2.36263675e-03, 9.97637363e-01],\n",
       "       [9.98395379e-01, 1.60462128e-03],\n",
       "       [1.51513485e-04, 9.99848487e-01],\n",
       "       [6.19481854e-04, 9.99380518e-01],\n",
       "       [9.85438775e-01, 1.45612247e-02],\n",
       "       [9.94731411e-01, 5.26858941e-03],\n",
       "       [9.93064658e-01, 6.93534235e-03],\n",
       "       [9.78486496e-01, 2.15135040e-02],\n",
       "       [9.08606112e-01, 9.13938884e-02],\n",
       "       [1.60277788e-03, 9.98397222e-01],\n",
       "       [9.88276390e-01, 1.17236104e-02],\n",
       "       [8.85233540e-03, 9.91147665e-01],\n",
       "       [9.91522288e-01, 8.47771156e-03],\n",
       "       [8.62023664e-04, 9.99137976e-01],\n",
       "       [9.97990644e-01, 2.00935606e-03],\n",
       "       [9.87623701e-01, 1.23762988e-02],\n",
       "       [1.51159264e-05, 9.99984884e-01],\n",
       "       [9.99406580e-01, 5.93420197e-04],\n",
       "       [9.64522315e-01, 3.54776845e-02],\n",
       "       [1.00075487e-01, 8.99924513e-01],\n",
       "       [9.96756762e-01, 3.24323782e-03],\n",
       "       [9.89788038e-01, 1.02119620e-02],\n",
       "       [9.92958873e-01, 7.04112741e-03],\n",
       "       [4.45655227e-07, 9.99999554e-01],\n",
       "       [4.94779436e-04, 9.99505221e-01],\n",
       "       [9.97718409e-01, 2.28159092e-03],\n",
       "       [9.93231358e-01, 6.76864188e-03],\n",
       "       [9.10592973e-01, 8.94070266e-02],\n",
       "       [9.96003794e-01, 3.99620559e-03],\n",
       "       [9.65555079e-01, 3.44449213e-02],\n",
       "       [1.17694427e-03, 9.98823056e-01],\n",
       "       [9.96756762e-01, 3.24323782e-03],\n",
       "       [9.89788038e-01, 1.02119620e-02],\n",
       "       [1.65084358e-03, 9.98349156e-01],\n",
       "       [9.79309139e-01, 2.06908614e-02],\n",
       "       [9.94408267e-01, 5.59173308e-03],\n",
       "       [9.82482033e-01, 1.75179672e-02],\n",
       "       [9.98120767e-01, 1.87923285e-03],\n",
       "       [9.99097967e-01, 9.02033451e-04],\n",
       "       [9.82357170e-01, 1.76428302e-02],\n",
       "       [9.98005089e-01, 1.99491063e-03],\n",
       "       [9.99406580e-01, 5.93420197e-04],\n",
       "       [9.89788038e-01, 1.02119620e-02],\n",
       "       [9.94065422e-01, 5.93457820e-03],\n",
       "       [9.82482033e-01, 1.75179672e-02],\n",
       "       [9.97990644e-01, 2.00935606e-03],\n",
       "       [1.55770744e-06, 9.99998442e-01],\n",
       "       [9.99406580e-01, 5.93420197e-04],\n",
       "       [9.50060377e-01, 4.99396226e-02],\n",
       "       [9.96756762e-01, 3.24323782e-03],\n",
       "       [8.87141949e-01, 1.12858051e-01],\n",
       "       [1.47391404e-03, 9.98526086e-01],\n",
       "       [9.94065422e-01, 5.93457820e-03],\n",
       "       [1.63885891e-05, 9.99983611e-01],\n",
       "       [9.05619994e-01, 9.43800061e-02],\n",
       "       [9.96063512e-01, 3.93648796e-03],\n",
       "       [9.98708096e-01, 1.29190373e-03],\n",
       "       [9.98974899e-01, 1.02510133e-03],\n",
       "       [9.98120767e-01, 1.87923285e-03],\n",
       "       [9.99406580e-01, 5.93420197e-04],\n",
       "       [9.70106911e-01, 2.98930887e-02],\n",
       "       [9.98911740e-01, 1.08825963e-03],\n",
       "       [3.07644135e-04, 9.99692356e-01],\n",
       "       [9.96756762e-01, 3.24323782e-03],\n",
       "       [3.41779373e-05, 9.99965822e-01],\n",
       "       [1.93603984e-07, 9.99999806e-01],\n",
       "       [2.67812593e-03, 9.97321874e-01],\n",
       "       [7.96785399e-04, 9.99203215e-01],\n",
       "       [9.89788038e-01, 1.02119620e-02],\n",
       "       [9.94367923e-01, 5.63207664e-03],\n",
       "       [9.82482033e-01, 1.75179672e-02],\n",
       "       [2.88058542e-03, 9.97119415e-01],\n",
       "       [9.70106911e-01, 2.98930887e-02],\n",
       "       [9.98229749e-01, 1.77025092e-03],\n",
       "       [9.98974899e-01, 1.02510133e-03],\n",
       "       [9.70573830e-01, 2.94261703e-02],\n",
       "       [9.98911740e-01, 1.08825963e-03],\n",
       "       [1.76707377e-01, 8.23292623e-01],\n",
       "       [5.59108510e-03, 9.94408915e-01],\n",
       "       [1.68107974e-02, 9.83189203e-01],\n",
       "       [9.98887106e-01, 1.11289405e-03],\n",
       "       [9.94731411e-01, 5.26858941e-03],\n",
       "       [9.98005089e-01, 1.99491063e-03],\n",
       "       [1.41111735e-04, 9.99858888e-01],\n",
       "       [2.97967197e-02, 9.70203280e-01],\n",
       "       [9.73451335e-01, 2.65486651e-02],\n",
       "       [9.92800976e-01, 7.19902357e-03],\n",
       "       [5.58749085e-02, 9.44125092e-01],\n",
       "       [9.99402277e-01, 5.97723316e-04],\n",
       "       [1.43685026e-04, 9.99856315e-01],\n",
       "       [9.82516521e-01, 1.74834793e-02],\n",
       "       [9.94408267e-01, 5.59173308e-03],\n",
       "       [1.07480527e-01, 8.92519473e-01],\n",
       "       [9.97855424e-01, 2.14457556e-03],\n",
       "       [9.25299171e-01, 7.47008292e-02],\n",
       "       [9.99406580e-01, 5.93420197e-04],\n",
       "       [9.96756762e-01, 3.24323782e-03],\n",
       "       [9.98903853e-01, 1.09614709e-03],\n",
       "       [9.97990644e-01, 2.00935606e-03],\n",
       "       [9.91276019e-03, 9.90087240e-01],\n",
       "       [2.39760473e-04, 9.99760240e-01],\n",
       "       [9.83482940e-01, 1.65170597e-02],\n",
       "       [9.96330070e-01, 3.66993002e-03],\n",
       "       [9.98911740e-01, 1.08825963e-03],\n",
       "       [9.98903853e-01, 1.09614709e-03],\n",
       "       [9.99406580e-01, 5.93420197e-04],\n",
       "       [9.96944604e-01, 3.05539560e-03],\n",
       "       [1.18416027e-02, 9.88158397e-01],\n",
       "       [5.65586708e-05, 9.99943441e-01],\n",
       "       [1.86237953e-01, 8.13762047e-01],\n",
       "       [9.92280983e-01, 7.71901718e-03],\n",
       "       [1.50221690e-05, 9.99984978e-01],\n",
       "       [9.60946378e-01, 3.90536221e-02],\n",
       "       [9.97990644e-01, 2.00935606e-03],\n",
       "       [9.31912331e-01, 6.80876686e-02],\n",
       "       [9.98911740e-01, 1.08825963e-03],\n",
       "       [9.99406580e-01, 5.93420197e-04],\n",
       "       [4.65066627e-02, 9.53493337e-01],\n",
       "       [9.96557412e-01, 3.44258849e-03],\n",
       "       [5.96465533e-06, 9.99994035e-01],\n",
       "       [1.08409763e-01, 8.91590237e-01],\n",
       "       [9.99234901e-01, 7.65098601e-04],\n",
       "       [9.98229749e-01, 1.77025092e-03],\n",
       "       [2.53001325e-03, 9.97469987e-01],\n",
       "       [1.87004933e-04, 9.99812995e-01],\n",
       "       [9.96944604e-01, 3.05539560e-03],\n",
       "       [9.98658411e-01, 1.34158932e-03],\n",
       "       [9.98005089e-01, 1.99491063e-03],\n",
       "       [9.91202430e-01, 8.79756982e-03],\n",
       "       [9.97990644e-01, 2.00935606e-03],\n",
       "       [8.85105705e-06, 9.99991149e-01],\n",
       "       [9.97021745e-01, 2.97825549e-03],\n",
       "       [3.48799881e-03, 9.96512001e-01],\n",
       "       [9.96584330e-01, 3.41566974e-03],\n",
       "       [3.12578846e-02, 9.68742115e-01],\n",
       "       [1.06790870e-02, 9.89320913e-01],\n",
       "       [9.12646322e-02, 9.08735368e-01],\n",
       "       [9.87284008e-01, 1.27159923e-02],\n",
       "       [9.89647790e-01, 1.03522099e-02],\n",
       "       [3.30989170e-06, 9.99996690e-01],\n",
       "       [9.38195825e-01, 6.18041745e-02],\n",
       "       [9.99128675e-01, 8.71325370e-04],\n",
       "       [9.69239155e-01, 3.07608454e-02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = lr.predict_proba( X_test ) \n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c080442e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.87923285e-03, 1.77025092e-03, 9.99803518e-01, 1.75179672e-02,\n",
       "       5.59173308e-03, 4.48334276e-01, 9.97946020e-01, 2.38216491e-02,\n",
       "       1.40289575e-03, 3.44258849e-03, 7.24293521e-04, 1.86572114e-03,\n",
       "       9.99453802e-01, 1.02119620e-02, 1.02119620e-02, 1.09693596e-03,\n",
       "       8.83821522e-01, 1.08825963e-03, 1.08825963e-03, 9.62440163e-03,\n",
       "       3.45746032e-03, 2.68922871e-01, 9.99548232e-01, 9.57346399e-01,\n",
       "       4.11588442e-03, 5.59173308e-03, 9.99998235e-01, 1.07952819e-03,\n",
       "       5.63207664e-03, 7.19895413e-03, 9.99099453e-01, 9.77390836e-01,\n",
       "       3.05539560e-03, 3.34459321e-01, 9.99862321e-01, 1.77025092e-03,\n",
       "       1.82897629e-02, 1.87923285e-03, 3.44258849e-03, 1.59027133e-02,\n",
       "       1.02510133e-03, 9.96608883e-01, 5.93457820e-03, 2.46851514e-02,\n",
       "       8.74190553e-01, 9.99824704e-01, 9.99848006e-01, 9.94128601e-01,\n",
       "       3.12885599e-02, 9.93707964e-01, 1.77025092e-03, 8.71325370e-04,\n",
       "       9.62440163e-03, 1.08825963e-03, 7.71901718e-03, 1.22763178e-02,\n",
       "       9.99985788e-01, 9.79805833e-01, 9.99637227e-01, 1.99491063e-03,\n",
       "       3.24323782e-03, 1.16401429e-02, 1.87923285e-03, 9.99187732e-01,\n",
       "       5.65278966e-01, 1.65874726e-02, 1.00035519e-02, 9.97637363e-01,\n",
       "       1.60462128e-03, 9.99848487e-01, 9.99380518e-01, 1.45612247e-02,\n",
       "       5.26858941e-03, 6.93534235e-03, 2.15135040e-02, 9.13938884e-02,\n",
       "       9.98397222e-01, 1.17236104e-02, 9.91147665e-01, 8.47771156e-03,\n",
       "       9.99137976e-01, 2.00935606e-03, 1.23762988e-02, 9.99984884e-01,\n",
       "       5.93420197e-04, 3.54776845e-02, 8.99924513e-01, 3.24323782e-03,\n",
       "       1.02119620e-02, 7.04112741e-03, 9.99999554e-01, 9.99505221e-01,\n",
       "       2.28159092e-03, 6.76864188e-03, 8.94070266e-02, 3.99620559e-03,\n",
       "       3.44449213e-02, 9.98823056e-01, 3.24323782e-03, 1.02119620e-02,\n",
       "       9.98349156e-01, 2.06908614e-02, 5.59173308e-03, 1.75179672e-02,\n",
       "       1.87923285e-03, 9.02033451e-04, 1.76428302e-02, 1.99491063e-03,\n",
       "       5.93420197e-04, 1.02119620e-02, 5.93457820e-03, 1.75179672e-02,\n",
       "       2.00935606e-03, 9.99998442e-01, 5.93420197e-04, 4.99396226e-02,\n",
       "       3.24323782e-03, 1.12858051e-01, 9.98526086e-01, 5.93457820e-03,\n",
       "       9.99983611e-01, 9.43800061e-02, 3.93648796e-03, 1.29190373e-03,\n",
       "       1.02510133e-03, 1.87923285e-03, 5.93420197e-04, 2.98930887e-02,\n",
       "       1.08825963e-03, 9.99692356e-01, 3.24323782e-03, 9.99965822e-01,\n",
       "       9.99999806e-01, 9.97321874e-01, 9.99203215e-01, 1.02119620e-02,\n",
       "       5.63207664e-03, 1.75179672e-02, 9.97119415e-01, 2.98930887e-02,\n",
       "       1.77025092e-03, 1.02510133e-03, 2.94261703e-02, 1.08825963e-03,\n",
       "       8.23292623e-01, 9.94408915e-01, 9.83189203e-01, 1.11289405e-03,\n",
       "       5.26858941e-03, 1.99491063e-03, 9.99858888e-01, 9.70203280e-01,\n",
       "       2.65486651e-02, 7.19902357e-03, 9.44125092e-01, 5.97723316e-04,\n",
       "       9.99856315e-01, 1.74834793e-02, 5.59173308e-03, 8.92519473e-01,\n",
       "       2.14457556e-03, 7.47008292e-02, 5.93420197e-04, 3.24323782e-03,\n",
       "       1.09614709e-03, 2.00935606e-03, 9.90087240e-01, 9.99760240e-01,\n",
       "       1.65170597e-02, 3.66993002e-03, 1.08825963e-03, 1.09614709e-03,\n",
       "       5.93420197e-04, 3.05539560e-03, 9.88158397e-01, 9.99943441e-01,\n",
       "       8.13762047e-01, 7.71901718e-03, 9.99984978e-01, 3.90536221e-02,\n",
       "       2.00935606e-03, 6.80876686e-02, 1.08825963e-03, 5.93420197e-04,\n",
       "       9.53493337e-01, 3.44258849e-03, 9.99994035e-01, 8.91590237e-01,\n",
       "       7.65098601e-04, 1.77025092e-03, 9.97469987e-01, 9.99812995e-01,\n",
       "       3.05539560e-03, 1.34158932e-03, 1.99491063e-03, 8.79756982e-03,\n",
       "       2.00935606e-03, 9.99991149e-01, 2.97825549e-03, 9.96512001e-01,\n",
       "       3.41566974e-03, 9.68742115e-01, 9.89320913e-01, 9.08735368e-01,\n",
       "       1.27159923e-02, 1.03522099e-02, 9.99996690e-01, 6.18041745e-02,\n",
       "       8.71325370e-04, 3.07608454e-02])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob[:,1] # P(y==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef12f9b5",
   "metadata": {},
   "source": [
    "#### ROC-Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a2b9e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thres = roc_curve(y_test, y_pred_prob[:,1])\n",
    "plt.scatter(fpr, tpr, c='red')\n",
    "plt.plot(fpr, tpr, c='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3bd2bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9966787439613526"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b53337f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc_score(y_test, y_pred_prob[:,1]) ,\n",
    "                                  name='Logistic Regression')\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "999507b3-c7ed-4d99-942d-c879b35e0af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[137   1]\n",
      " [  6  66]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffab0794-1247-4ca6-9ca9-6df00fbf1f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(137+66)/210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f34e069c-78c7-48ad-8b5f-ef9934ce7536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "143e60ad-8d85-4e4f-8bee-5700522c576f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0aa796f-847a-4e02-ac46-86f3bb1a96b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty=None)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7be11dad-964e-4b28-97fa-d5de96ac7c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear',penalty='l1')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8142049c-e095-4ba1-83ba-f8cdda0e36eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       138\n",
      "           1       0.99      0.92      0.95        72\n",
      "\n",
      "    accuracy                           0.97       210\n",
      "   macro avg       0.97      0.95      0.96       210\n",
      "weighted avg       0.97      0.97      0.97       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( classification_report(y_test, y_pred) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e4a686-80f0-46a9-80d8-4df4bc2cab66",
   "metadata": {},
   "source": [
    "#### Human resources analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a811dc6-7e62-494e-8b88-488b8e073774",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = pd.read_csv(\"D:/Training/Academy/ML(Python)/Cases/human-resources-analytics/HR_comma_sep.csv\")\n",
    "X, y = hr.drop('left', axis=1), hr['left']\n",
    "ohe = OneHotEncoder(drop='first', sparse_output=False).set_output(transform='pandas')\n",
    "col_trnf = ColumnTransformer([('OHE',ohe, make_column_selector(dtype_include=object) )],\n",
    "                             remainder='passthrough',\n",
    "                             verbose_feature_names_out=False)\n",
    "col_trnf = col_trnf.set_output(transform='pandas')\n",
    "X = col_trnf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90f03953-9a17-406f-afe8-4bc2eeefc68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "964af1ed-55ab-4d53-8961-5e57618f086f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      3429\n",
      "           1       0.64      0.37      0.47      1070\n",
      "\n",
      "    accuracy                           0.80      4499\n",
      "   macro avg       0.73      0.65      0.67      4499\n",
      "weighted avg       0.78      0.80      0.78      4499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear',penalty='l1')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print( classification_report(y_test, y_pred) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "856b662c-d28d-4660-9bdb-3afc0a74a6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      3429\n",
      "           1       0.64      0.40      0.49      1070\n",
      "\n",
      "    accuracy                           0.80      4499\n",
      "   macro avg       0.74      0.66      0.68      4499\n",
      "weighted avg       0.79      0.80      0.79      4499\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs',penalty='l2')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print( classification_report(y_test, y_pred) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41025f58-eb93-42d4-8d4c-baec9e0316be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      3429\n",
      "           1       0.66      0.41      0.51      1070\n",
      "\n",
      "    accuracy                           0.81      4499\n",
      "   macro avg       0.75      0.67      0.69      4499\n",
      "weighted avg       0.79      0.81      0.79      4499\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs',penalty=None)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print( classification_report(y_test, y_pred) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedef6cc-8f47-4501-a9f9-b58a6dd57f70",
   "metadata": {},
   "source": [
    "Hyper-params Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55f6aa0a-cc52-4845-b9f8-3e09be7448c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "solver",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "penalty",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f3bce6bf-6cd2-4f00-bcde-adf72035eade",
       "rows": [
        [
         "1",
         "lbfgs",
         null,
         "0.8090686819293176"
        ],
        [
         "0",
         "lbfgs",
         "l2",
         "0.8039564347632807"
        ],
        [
         "2",
         "newton-cg",
         "l2",
         "0.7995110024449877"
        ],
        [
         "3",
         "newton-cg",
         null,
         "0.7992887308290731"
        ],
        [
         "4",
         "newton-cholesky",
         "l2",
         "0.7990664592131584"
        ],
        [
         "5",
         "newton-cholesky",
         null,
         "0.7990664592131584"
        ],
        [
         "8",
         "saga",
         "l2",
         "0.757723938653034"
        ],
        [
         "9",
         "saga",
         null,
         "0.757723938653034"
        ],
        [
         "6",
         "sag",
         "l2",
         "0.7506112469437652"
        ],
        [
         "7",
         "sag",
         null,
         "0.7503889753278506"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solver</th>\n",
       "      <th>penalty</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>None</td>\n",
       "      <td>0.809069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.803956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>newton-cg</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.799511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newton-cg</td>\n",
       "      <td>None</td>\n",
       "      <td>0.799289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.799066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>None</td>\n",
       "      <td>0.799066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.757724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>saga</td>\n",
       "      <td>None</td>\n",
       "      <td>0.757724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sag</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.750611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sag</td>\n",
       "      <td>None</td>\n",
       "      <td>0.750389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            solver penalty     score\n",
       "1            lbfgs    None  0.809069\n",
       "0            lbfgs      l2  0.803956\n",
       "2        newton-cg      l2  0.799511\n",
       "3        newton-cg    None  0.799289\n",
       "4  newton-cholesky      l2  0.799066\n",
       "5  newton-cholesky    None  0.799066\n",
       "8             saga      l2  0.757724\n",
       "9             saga    None  0.757724\n",
       "6              sag      l2  0.750611\n",
       "7              sag    None  0.750389"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solvers = ['lbfgs','newton-cg','newton-cholesky','sag','saga']\n",
    "penalties = ['l2', None]\n",
    "scores = []\n",
    "for s in solvers:\n",
    "    for p in penalties:\n",
    "        lr = LogisticRegression(penalty=p ,solver=s)\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_pred = lr.predict(X_test)\n",
    "        scores.append([s, p, accuracy_score(y_test, y_pred)])\n",
    "df_scores = pd.DataFrame(scores, columns=['solver','penalty','score'])\n",
    "df_scores.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2340ceb6-2b25-41cd-a3a9-81a6e45d019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "solver",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "penalty",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "C",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "e8ef1090-277a-4eb5-8542-9f9a2d69ac75",
       "rows": [
        [
         "15",
         "lbfgs",
         "l2",
         "11.842315789473686",
         "0.813291842631696"
        ],
        [
         "5",
         "lbfgs",
         "l2",
         "3.948105263157895",
         "0.8130695710157813"
        ],
        [
         "2",
         "lbfgs",
         "l2",
         "1.579842105263158",
         "0.8124027561680374"
        ],
        [
         "11",
         "lbfgs",
         "l2",
         "8.68463157894737",
         "0.8112913980884641"
        ],
        [
         "12",
         "lbfgs",
         "l2",
         "9.474052631578948",
         "0.8108468548566348"
        ],
        [
         "4",
         "lbfgs",
         "l2",
         "3.158684210526316",
         "0.8092909535452323"
        ],
        [
         "32",
         "lbfgs",
         null,
         "9.474052631578948",
         "0.8090686819293176"
        ],
        [
         "25",
         "lbfgs",
         null,
         "3.948105263157895",
         "0.8090686819293176"
        ],
        [
         "26",
         "lbfgs",
         null,
         "4.7375263157894745",
         "0.8090686819293176"
        ],
        [
         "27",
         "lbfgs",
         null,
         "5.5269473684210535",
         "0.8090686819293176"
        ],
        [
         "29",
         "lbfgs",
         null,
         "7.1057894736842115",
         "0.8090686819293176"
        ],
        [
         "30",
         "lbfgs",
         null,
         "7.895210526315791",
         "0.8090686819293176"
        ],
        [
         "31",
         "lbfgs",
         null,
         "8.68463157894737",
         "0.8090686819293176"
        ],
        [
         "36",
         "lbfgs",
         null,
         "12.631736842105264",
         "0.8090686819293176"
        ],
        [
         "23",
         "lbfgs",
         null,
         "2.369263157894737",
         "0.8090686819293176"
        ],
        [
         "33",
         "lbfgs",
         null,
         "10.263473684210526",
         "0.8090686819293176"
        ],
        [
         "34",
         "lbfgs",
         null,
         "11.052894736842106",
         "0.8090686819293176"
        ],
        [
         "35",
         "lbfgs",
         null,
         "11.842315789473686",
         "0.8090686819293176"
        ],
        [
         "37",
         "lbfgs",
         null,
         "13.421157894736842",
         "0.8090686819293176"
        ],
        [
         "38",
         "lbfgs",
         null,
         "14.210578947368422",
         "0.8090686819293176"
        ],
        [
         "39",
         "lbfgs",
         null,
         "15.0",
         "0.8090686819293176"
        ],
        [
         "24",
         "lbfgs",
         null,
         "3.158684210526316",
         "0.8090686819293176"
        ],
        [
         "28",
         "lbfgs",
         null,
         "6.3163684210526325",
         "0.8090686819293176"
        ],
        [
         "22",
         "lbfgs",
         null,
         "1.579842105263158",
         "0.8090686819293176"
        ],
        [
         "20",
         "lbfgs",
         null,
         "0.001",
         "0.8090686819293176"
        ],
        [
         "21",
         "lbfgs",
         null,
         "0.790421052631579",
         "0.8090686819293176"
        ],
        [
         "13",
         "lbfgs",
         "l2",
         "10.263473684210526",
         "0.808846410313403"
        ],
        [
         "8",
         "lbfgs",
         "l2",
         "6.3163684210526325",
         "0.808846410313403"
        ],
        [
         "7",
         "lbfgs",
         "l2",
         "5.5269473684210535",
         "0.8084018670815737"
        ],
        [
         "3",
         "lbfgs",
         "l2",
         "2.369263157894737",
         "0.808179595465659"
        ],
        [
         "18",
         "lbfgs",
         "l2",
         "14.210578947368422",
         "0.8079573238497444"
        ],
        [
         "10",
         "lbfgs",
         "l2",
         "7.895210526315791",
         "0.8079573238497444"
        ],
        [
         "6",
         "lbfgs",
         "l2",
         "4.7375263157894745",
         "0.8077350522338297"
        ],
        [
         "19",
         "lbfgs",
         "l2",
         "15.0",
         "0.8072905090020004"
        ],
        [
         "14",
         "lbfgs",
         "l2",
         "11.052894736842106",
         "0.8070682373860858"
        ],
        [
         "9",
         "lbfgs",
         "l2",
         "7.1057894736842115",
         "0.8064014225383419"
        ],
        [
         "17",
         "lbfgs",
         "l2",
         "13.421157894736842",
         "0.8061791509224272"
        ],
        [
         "1",
         "lbfgs",
         "l2",
         "0.790421052631579",
         "0.8057346076905979"
        ],
        [
         "16",
         "lbfgs",
         "l2",
         "12.631736842105264",
         "0.8032896199155368"
        ],
        [
         "41",
         "newton-cg",
         "l2",
         "0.790421052631579",
         "0.7995110024449877"
        ],
        [
         "81",
         "newton-cholesky",
         "l2",
         "0.790421052631579",
         "0.7995110024449877"
        ],
        [
         "64",
         "newton-cg",
         null,
         "3.158684210526316",
         "0.7992887308290731"
        ],
        [
         "60",
         "newton-cg",
         null,
         "0.001",
         "0.7992887308290731"
        ],
        [
         "61",
         "newton-cg",
         null,
         "0.790421052631579",
         "0.7992887308290731"
        ],
        [
         "62",
         "newton-cg",
         null,
         "1.579842105263158",
         "0.7992887308290731"
        ],
        [
         "74",
         "newton-cg",
         null,
         "11.052894736842106",
         "0.7992887308290731"
        ],
        [
         "63",
         "newton-cg",
         null,
         "2.369263157894737",
         "0.7992887308290731"
        ],
        [
         "68",
         "newton-cg",
         null,
         "6.3163684210526325",
         "0.7992887308290731"
        ],
        [
         "65",
         "newton-cg",
         null,
         "3.948105263157895",
         "0.7992887308290731"
        ],
        [
         "66",
         "newton-cg",
         null,
         "4.7375263157894745",
         "0.7992887308290731"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 200
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solver</th>\n",
       "      <th>penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>11.842316</td>\n",
       "      <td>0.813292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>3.948105</td>\n",
       "      <td>0.813070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.579842</td>\n",
       "      <td>0.812403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>8.684632</td>\n",
       "      <td>0.811291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>9.474053</td>\n",
       "      <td>0.810847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>sag</td>\n",
       "      <td>None</td>\n",
       "      <td>3.158684</td>\n",
       "      <td>0.750611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>sag</td>\n",
       "      <td>None</td>\n",
       "      <td>10.263474</td>\n",
       "      <td>0.750611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>sag</td>\n",
       "      <td>None</td>\n",
       "      <td>9.474053</td>\n",
       "      <td>0.750611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>sag</td>\n",
       "      <td>None</td>\n",
       "      <td>8.684632</td>\n",
       "      <td>0.750611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>sag</td>\n",
       "      <td>l2</td>\n",
       "      <td>2.369263</td>\n",
       "      <td>0.750611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    solver penalty          C     score\n",
       "15   lbfgs      l2  11.842316  0.813292\n",
       "5    lbfgs      l2   3.948105  0.813070\n",
       "2    lbfgs      l2   1.579842  0.812403\n",
       "11   lbfgs      l2   8.684632  0.811291\n",
       "12   lbfgs      l2   9.474053  0.810847\n",
       "..     ...     ...        ...       ...\n",
       "144    sag    None   3.158684  0.750611\n",
       "153    sag    None  10.263474  0.750611\n",
       "152    sag    None   9.474053  0.750611\n",
       "151    sag    None   8.684632  0.750611\n",
       "123    sag      l2   2.369263  0.750611\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solvers = ['lbfgs','newton-cg','newton-cholesky','sag','saga']\n",
    "Cs = np.linspace(0.001, 15, 20)\n",
    "penalties = ['l2', None]\n",
    "scores = []\n",
    "for s in solvers:\n",
    "    for p in penalties:\n",
    "        for c in Cs:\n",
    "            lr = LogisticRegression(penalty=p ,solver=s, C=c)\n",
    "            lr.fit(X_train, y_train)\n",
    "            y_pred = lr.predict(X_test)\n",
    "            scores.append([s, p,c, accuracy_score(y_test, y_pred)])\n",
    "df_scores = pd.DataFrame(scores, columns=['solver','penalty','C','score'])\n",
    "df_scores.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8742c699-4c83-4f83-829d-be79a1a85897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
